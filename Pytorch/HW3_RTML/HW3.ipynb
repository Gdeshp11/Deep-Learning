{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb28ca14910>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
    "    'ship', 'truck'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_path = './'\n",
    "cifar = datasets.CIFAR10(data_path,\n",
    "                         train=True,\n",
    "                         download=True,\n",
    "                         transform=transforms.Compose([\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                  (0.2470, 0.2435, 0.2616))\n",
    "                         ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_val = datasets.CIFAR10(data_path,\n",
    "                             train=False,\n",
    "                             download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                      (0.2470, 0.2435, 0.2616))\n",
    "                             ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
    "    'ship', 'truck'\n",
    "]\n",
    "cifar10 = [(img, label_map[label]) for img, label in cifar]\n",
    "cifar10_val = [(img, label_map[label]) for img, label in cifar_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "# defining training device to be GPU if available\n",
    "device = (torch.device('cuda')\n",
    "          if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)  # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 12:42:00.734665 Epoch 1, Training loss 2.0272156626672087\n",
      "2022-03-28 12:42:32.193694 Epoch 10, Training loss 1.157125376145858\n",
      "2022-03-28 12:43:07.705250 Epoch 20, Training loss 0.9849611330215279\n",
      "2022-03-28 12:43:42.943194 Epoch 30, Training loss 0.9046245566414445\n",
      "2022-03-28 12:44:18.849933 Epoch 40, Training loss 0.8509574451714831\n",
      "2022-03-28 12:44:56.082982 Epoch 50, Training loss 0.8095788680531485\n",
      "2022-03-28 12:45:33.139916 Epoch 60, Training loss 0.7747540147331975\n",
      "2022-03-28 12:46:05.542413 Epoch 70, Training loss 0.7477211259743747\n",
      "2022-03-28 12:46:38.476941 Epoch 80, Training loss 0.7259142484582598\n",
      "2022-03-28 12:47:16.956521 Epoch 90, Training loss 0.7057621136803152\n",
      "2022-03-28 12:47:51.604055 Epoch 100, Training loss 0.683885840808644\n",
      "2022-03-28 12:48:25.457080 Epoch 110, Training loss 0.669882084326366\n",
      "2022-03-28 12:48:59.248704 Epoch 120, Training loss 0.6544880609759285\n",
      "2022-03-28 12:49:33.843939 Epoch 130, Training loss 0.6395354754936969\n",
      "2022-03-28 12:50:06.782122 Epoch 140, Training loss 0.6266810314353469\n",
      "2022-03-28 12:50:39.004558 Epoch 150, Training loss 0.6164708535765748\n",
      "2022-03-28 12:51:10.496739 Epoch 160, Training loss 0.6035987648284039\n",
      "2022-03-28 12:51:40.571025 Epoch 170, Training loss 0.5937166106899071\n",
      "2022-03-28 12:52:11.323053 Epoch 180, Training loss 0.5865671864860807\n",
      "2022-03-28 12:52:41.314321 Epoch 190, Training loss 0.577285412822843\n",
      "2022-03-28 12:53:11.232602 Epoch 200, Training loss 0.5677451912856772\n",
      "2022-03-28 12:53:41.628178 Epoch 210, Training loss 0.5612886184088105\n",
      "2022-03-28 12:54:11.634127 Epoch 220, Training loss 0.5561231530802634\n",
      "2022-03-28 12:54:41.516570 Epoch 230, Training loss 0.549857304148052\n",
      "2022-03-28 12:55:11.203895 Epoch 240, Training loss 0.5434133841672821\n",
      "2022-03-28 12:55:40.851457 Epoch 250, Training loss 0.5390962844766924\n",
      "2022-03-28 12:56:10.700136 Epoch 260, Training loss 0.5314929121747956\n",
      "2022-03-28 12:56:41.545484 Epoch 270, Training loss 0.5295560300502631\n",
      "2022-03-28 12:57:11.745982 Epoch 280, Training loss 0.5239546164832152\n",
      "2022-03-28 12:57:41.750499 Epoch 290, Training loss 0.5211067410266917\n",
      "2022-03-28 12:58:12.030909 Epoch 300, Training loss 0.5136402560698102\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = Net()  # <1>\n",
    "model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.81\n",
      "Accuracy val: 0.62\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)  # <1>\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)  # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct / total))\n",
    "\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), data_path + 'cifar10_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Net()  # <1>\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'cifar10_cnn.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1,\n",
    "                               n_chans1 // 2,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2,\n",
    "                               n_chans1 // 2,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 12:58:17.893638 Epoch 1, Training loss 2.2579623297657196\n",
      "2022-03-28 12:58:52.081774 Epoch 10, Training loss 1.1792650334822856\n",
      "2022-03-28 12:59:30.364551 Epoch 20, Training loss 0.9259592535550637\n",
      "2022-03-28 13:00:08.422976 Epoch 30, Training loss 0.8019527055113517\n",
      "2022-03-28 13:00:46.621873 Epoch 40, Training loss 0.7234853408906771\n",
      "2022-03-28 13:01:24.661155 Epoch 50, Training loss 0.6681999755103875\n",
      "2022-03-28 13:02:02.484709 Epoch 60, Training loss 0.6303327808828305\n",
      "2022-03-28 13:02:41.330534 Epoch 70, Training loss 0.599074250063323\n",
      "2022-03-28 13:03:19.021301 Epoch 80, Training loss 0.5728257916620015\n",
      "2022-03-28 13:03:56.914382 Epoch 90, Training loss 0.552716749917973\n",
      "2022-03-28 13:04:35.650234 Epoch 100, Training loss 0.5328375514968277\n",
      "2022-03-28 13:05:13.365527 Epoch 110, Training loss 0.5137770429939565\n",
      "2022-03-28 13:05:51.451834 Epoch 120, Training loss 0.5001735438585586\n",
      "2022-03-28 13:06:29.507044 Epoch 130, Training loss 0.48676098947939667\n",
      "2022-03-28 13:07:07.473202 Epoch 140, Training loss 0.47590891753925996\n",
      "2022-03-28 13:07:46.245747 Epoch 150, Training loss 0.46499013477731543\n",
      "2022-03-28 13:08:24.825106 Epoch 160, Training loss 0.45607223226438703\n",
      "2022-03-28 13:09:03.197150 Epoch 170, Training loss 0.44713119930013673\n",
      "2022-03-28 13:09:41.196850 Epoch 180, Training loss 0.4414666173098337\n",
      "2022-03-28 13:10:19.264210 Epoch 190, Training loss 0.4348360436499271\n",
      "2022-03-28 13:10:57.029626 Epoch 200, Training loss 0.42565848407766704\n",
      "2022-03-28 13:11:34.964923 Epoch 210, Training loss 0.4184175498040436\n",
      "2022-03-28 13:12:13.057987 Epoch 220, Training loss 0.41272315769777884\n",
      "2022-03-28 13:12:51.017118 Epoch 230, Training loss 0.4071094390490781\n",
      "2022-03-28 13:13:28.872025 Epoch 240, Training loss 0.400361671958052\n",
      "2022-03-28 13:14:06.634993 Epoch 250, Training loss 0.39582494685373953\n",
      "2022-03-28 13:14:44.237584 Epoch 260, Training loss 0.39327546594011814\n",
      "2022-03-28 13:15:22.321636 Epoch 270, Training loss 0.3875649585710157\n",
      "2022-03-28 13:16:00.363983 Epoch 280, Training loss 0.3854740626366852\n",
      "2022-03-28 13:16:38.904092 Epoch 290, Training loss 0.37734199404868934\n",
      "2022-03-28 13:17:17.604764 Epoch 300, Training loss 0.3774834609854862\n",
      "Accuracy train: 0.83\n",
      "Accuracy val: 0.67\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar10,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "model = Net2(n_chans1=32)  # <1>\n",
    "model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    ")\n",
    "\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)  # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "\n",
    "all_acc_dict[\"depth\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), data_path + 'cifar10_cnn_2.pt')\n",
    "\n",
    "loaded_model = Net2()  # <1>\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'cifar10_cnn_2.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans,\n",
    "                              n_chans,\n",
    "                              kernel_size=3,\n",
    "                              padding=1,\n",
    "                              bias=False)  # <1>\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                      nonlinearity='relu')  # <2>\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(*(n_blocks *\n",
    "                                         [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 13:17:31.103375 Epoch 1, Training loss 1.6537252411513073\n",
      "2022-03-28 13:19:10.543659 Epoch 10, Training loss 0.8952865375734657\n",
      "2022-03-28 13:21:00.345388 Epoch 20, Training loss 0.7029523789272893\n",
      "2022-03-28 13:22:50.262821 Epoch 30, Training loss 0.5760862308999767\n",
      "2022-03-28 13:24:39.073742 Epoch 40, Training loss 0.47129336470152106\n",
      "2022-03-28 13:26:27.061611 Epoch 50, Training loss 0.3821954912579883\n",
      "2022-03-28 13:28:15.270538 Epoch 60, Training loss 0.3160720006908145\n",
      "2022-03-28 13:30:06.502863 Epoch 70, Training loss 0.2563716293410267\n",
      "2022-03-28 13:31:58.869709 Epoch 80, Training loss 0.21213952586283463\n",
      "2022-03-28 13:33:51.045559 Epoch 90, Training loss 0.15849795307764006\n",
      "2022-03-28 13:35:42.659678 Epoch 100, Training loss 0.13147679809719096\n",
      "2022-03-28 13:37:34.322841 Epoch 110, Training loss 0.11758544699877234\n",
      "2022-03-28 13:39:22.291453 Epoch 120, Training loss 0.10295337021989209\n",
      "2022-03-28 13:41:11.840542 Epoch 130, Training loss 0.07277637570405669\n",
      "2022-03-28 13:43:01.910636 Epoch 140, Training loss 0.07272199111397537\n",
      "2022-03-28 13:44:52.419072 Epoch 150, Training loss 0.06956887837794735\n",
      "2022-03-28 13:46:42.911211 Epoch 160, Training loss 0.050866806502108605\n",
      "2022-03-28 13:48:32.232575 Epoch 170, Training loss 0.03816312203488058\n",
      "2022-03-28 13:50:22.913224 Epoch 180, Training loss 0.019721455556754967\n",
      "2022-03-28 13:52:13.152750 Epoch 190, Training loss 0.00917560461534323\n",
      "2022-03-28 13:54:03.977573 Epoch 200, Training loss 0.09853903294536177\n",
      "2022-03-28 13:55:54.356326 Epoch 210, Training loss 0.008563512370458987\n",
      "2022-03-28 13:57:41.009445 Epoch 220, Training loss 0.004827992821088754\n",
      "2022-03-28 13:59:28.970852 Epoch 230, Training loss 0.0030320745564865\n",
      "2022-03-28 14:01:17.432995 Epoch 240, Training loss 0.0027480696585452744\n",
      "2022-03-28 14:03:08.156709 Epoch 250, Training loss 0.0019355594885454852\n",
      "2022-03-28 14:04:58.453214 Epoch 260, Training loss 0.08644726442392259\n",
      "2022-03-28 14:06:48.273611 Epoch 270, Training loss 0.006128810469017667\n",
      "2022-03-28 14:08:39.177588 Epoch 280, Training loss 0.002639349676100561\n",
      "2022-03-28 14:10:29.736328 Epoch 290, Training loss 0.002828358654620583\n",
      "2022-03-28 14:12:18.096166 Epoch 300, Training loss 0.001915564824169909\n",
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.66\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeep(n_chans1=32, n_blocks=10).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    ")\n",
    "\n",
    "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())  # <1>\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 14:12:34.924001 Epoch 1, Training loss 1.8529443972555877\n",
      "2022-03-28 14:14:24.901975 Epoch 10, Training loss 1.0290287321485827\n",
      "2022-03-28 14:16:27.023223 Epoch 20, Training loss 0.8332347395017629\n",
      "2022-03-28 14:18:27.747870 Epoch 30, Training loss 0.7107355670855783\n",
      "2022-03-28 14:20:28.783867 Epoch 40, Training loss 0.617741543580504\n",
      "2022-03-28 14:22:27.785151 Epoch 50, Training loss 0.5388303382317429\n",
      "2022-03-28 14:24:29.200062 Epoch 60, Training loss 0.478221152673292\n",
      "2022-03-28 14:26:30.370353 Epoch 70, Training loss 0.4247900950901039\n",
      "2022-03-28 14:28:32.745434 Epoch 80, Training loss 0.37776153782368316\n",
      "2022-03-28 14:30:33.984261 Epoch 90, Training loss 0.3467440060947252\n",
      "2022-03-28 14:32:35.735117 Epoch 100, Training loss 0.31754724077327784\n",
      "2022-03-28 14:34:37.905049 Epoch 110, Training loss 0.28845322587529715\n",
      "2022-03-28 14:36:40.149228 Epoch 120, Training loss 0.27854507338360446\n",
      "2022-03-28 14:38:44.471415 Epoch 130, Training loss 0.24163195132599463\n",
      "2022-03-28 14:40:49.306824 Epoch 140, Training loss 0.2633425065356752\n",
      "2022-03-28 14:42:53.149250 Epoch 150, Training loss 0.22731184460165554\n",
      "2022-03-28 14:44:58.937820 Epoch 160, Training loss 0.21270303548220784\n",
      "2022-03-28 14:47:05.713424 Epoch 170, Training loss 0.22873992676777608\n",
      "2022-03-28 14:49:12.866695 Epoch 180, Training loss 0.1829755539479463\n",
      "2022-03-28 14:51:18.873903 Epoch 190, Training loss 0.1806516802257589\n",
      "2022-03-28 14:53:26.024332 Epoch 200, Training loss 0.2651365652032521\n",
      "2022-03-28 14:55:38.267371 Epoch 210, Training loss 0.1692008322195324\n",
      "2022-03-28 14:57:49.074405 Epoch 220, Training loss 0.154908849398041\n",
      "2022-03-28 14:59:58.164085 Epoch 230, Training loss 0.16480137177211854\n",
      "2022-03-28 15:01:59.225206 Epoch 240, Training loss 0.15173996904926837\n",
      "2022-03-28 15:04:01.286181 Epoch 250, Training loss 0.20195340529046096\n",
      "2022-03-28 15:06:04.518047 Epoch 260, Training loss 0.3455650399979728\n",
      "2022-03-28 15:08:07.724385 Epoch 270, Training loss 0.16401738658204407\n",
      "2022-03-28 15:10:14.925629 Epoch 280, Training loss 0.1453302628586969\n",
      "2022-03-28 15:12:17.449979 Epoch 290, Training loss 0.17944593285508167\n",
      "2022-03-28 15:14:21.656415 Epoch 300, Training loss 0.1453189494283608\n",
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.67\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeep(n_chans1=32, n_blocks=10).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop_l2reg(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    ")\n",
    "all_acc_dict[\"Resnet l2 reg\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeepDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 15:26:56.322412 Epoch 1, Training loss 1.8857117900458138\n",
      "2022-03-28 15:28:39.937823 Epoch 10, Training loss 1.183483033991226\n",
      "2022-03-28 15:30:33.458388 Epoch 20, Training loss 1.0019492818723859\n",
      "2022-03-28 15:32:27.560152 Epoch 30, Training loss 0.9012617848413375\n",
      "2022-03-28 15:34:20.417570 Epoch 40, Training loss 0.8300152822299991\n",
      "2022-03-28 15:36:11.089144 Epoch 50, Training loss 0.772568424873035\n",
      "2022-03-28 15:38:02.729024 Epoch 60, Training loss 0.721823562098586\n",
      "2022-03-28 15:39:58.950338 Epoch 70, Training loss 0.6828312092577405\n",
      "2022-03-28 15:41:53.166647 Epoch 80, Training loss 0.638541258738169\n",
      "2022-03-28 15:43:47.100118 Epoch 90, Training loss 0.608074029273999\n",
      "2022-03-28 15:45:41.468615 Epoch 100, Training loss 0.5768273579876136\n",
      "2022-03-28 15:47:32.291132 Epoch 110, Training loss 0.5515036447845456\n",
      "2022-03-28 15:49:22.896113 Epoch 120, Training loss 0.5282897266661725\n",
      "2022-03-28 15:51:14.614294 Epoch 130, Training loss 0.50715550107648\n",
      "2022-03-28 15:53:04.300590 Epoch 140, Training loss 0.48402195395258685\n",
      "2022-03-28 15:54:52.829785 Epoch 150, Training loss 0.4718656920830307\n",
      "2022-03-28 15:56:44.048458 Epoch 160, Training loss 0.45317721965215396\n",
      "2022-03-28 15:58:38.708424 Epoch 170, Training loss 0.44157283124335284\n",
      "2022-03-28 16:00:28.959887 Epoch 180, Training loss 0.4210307513699507\n",
      "2022-03-28 16:02:17.910873 Epoch 190, Training loss 0.40720067531480203\n",
      "2022-03-28 16:04:10.487629 Epoch 200, Training loss 0.3993359050711098\n",
      "2022-03-28 16:05:59.583001 Epoch 210, Training loss 0.39461820383015495\n",
      "2022-03-28 16:07:52.268058 Epoch 220, Training loss 0.38405770777970016\n",
      "2022-03-28 16:09:47.336625 Epoch 230, Training loss 0.37507756900451983\n",
      "2022-03-28 16:11:37.890232 Epoch 240, Training loss 0.3661034868653778\n",
      "2022-03-28 16:13:31.648774 Epoch 250, Training loss 0.35831198279205184\n",
      "2022-03-28 16:15:25.129309 Epoch 260, Training loss 0.35203951743938733\n",
      "2022-03-28 16:17:18.927666 Epoch 270, Training loss 0.3452866602584224\n",
      "2022-03-28 16:19:11.964521 Epoch 280, Training loss 0.33819571667162657\n",
      "2022-03-28 16:21:05.428528 Epoch 290, Training loss 0.3337078652609035\n",
      "2022-03-28 16:22:57.790907 Epoch 300, Training loss 0.32530036158955006\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.61\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeepDropout(n_chans1=32, n_blocks=10).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"NetResDeepdropout\"] = validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NetBatchNorm(nn.Module):\n",
    "#     def __init__(self, n_chans1=32):\n",
    "#         super().__init__()\n",
    "#         self.n_chans1 = n_chans1\n",
    "#         self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "#         self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "#         self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, \n",
    "#                                padding=1)\n",
    "#         self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "#         self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "#         self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.conv1_batchnorm(self.conv1(x))\n",
    "#         out = F.max_pool2d(torch.tanh(out), 2)\n",
    "#         out = self.conv2_batchnorm(self.conv2(out))\n",
    "#         out = F.max_pool2d(torch.tanh(out), 2)\n",
    "#         out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "#         out = torch.tanh(self.fc1(out))\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "class NetResDeepBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1_batchnorm(self.conv1(x))),2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:45:18.085264 Epoch 1, Training loss 1.631086176161266\n",
      "2022-03-28 16:47:01.447299 Epoch 10, Training loss 0.8519168049859269\n",
      "2022-03-28 16:48:57.264420 Epoch 20, Training loss 0.6804067243624221\n",
      "2022-03-28 16:50:53.971188 Epoch 30, Training loss 0.5628214233824055\n",
      "2022-03-28 16:52:49.838432 Epoch 40, Training loss 0.46462158471955667\n",
      "2022-03-28 16:54:44.697111 Epoch 50, Training loss 0.3873430900561535\n",
      "2022-03-28 16:56:42.383493 Epoch 60, Training loss 0.3126164870074643\n",
      "2022-03-28 16:58:39.234902 Epoch 70, Training loss 0.24821490480009553\n",
      "2022-03-28 17:00:37.020036 Epoch 80, Training loss 0.2034750313681486\n",
      "2022-03-28 17:02:34.119584 Epoch 90, Training loss 0.1735704119967492\n",
      "2022-03-28 17:04:29.142659 Epoch 100, Training loss 0.12463425856340876\n",
      "2022-03-28 17:06:25.418819 Epoch 110, Training loss 0.10340226514984274\n",
      "2022-03-28 17:08:23.074665 Epoch 120, Training loss 0.09345086091769683\n",
      "2022-03-28 17:10:19.910265 Epoch 130, Training loss 0.08333995694632801\n",
      "2022-03-28 17:12:18.098775 Epoch 140, Training loss 0.07517880871248862\n",
      "2022-03-28 17:14:17.182558 Epoch 150, Training loss 0.050445957135830714\n",
      "2022-03-28 17:16:13.055815 Epoch 160, Training loss 0.06727504047036381\n",
      "2022-03-28 17:18:09.524731 Epoch 170, Training loss 0.03926217881419286\n",
      "2022-03-28 17:20:07.095574 Epoch 180, Training loss 0.03496915880260784\n",
      "2022-03-28 17:22:06.425617 Epoch 190, Training loss 0.025526502872775535\n",
      "2022-03-28 17:24:05.326959 Epoch 200, Training loss 0.020182654011861808\n",
      "2022-03-28 17:26:01.402057 Epoch 210, Training loss 0.05020878560822624\n",
      "2022-03-28 17:27:57.290417 Epoch 220, Training loss 0.01894164391127272\n",
      "2022-03-28 17:29:54.800840 Epoch 230, Training loss 0.018371192797775205\n",
      "2022-03-28 17:31:49.216235 Epoch 240, Training loss 0.02685857812367568\n",
      "2022-03-28 17:33:45.054009 Epoch 250, Training loss 0.029605551263364508\n",
      "2022-03-28 17:35:42.359389 Epoch 260, Training loss 0.020374950806303915\n",
      "2022-03-28 17:37:38.974970 Epoch 270, Training loss 0.01756266302051683\n",
      "2022-03-28 17:39:38.655021 Epoch 280, Training loss 0.015441120392248413\n",
      "2022-03-28 17:41:40.197818 Epoch 290, Training loss 0.008592094878589883\n",
      "2022-03-28 17:43:43.668154 Epoch 300, Training loss 0.015292594063831457\n",
      "Accuracy train: 0.76\n",
      "Accuracy val: 0.57\n"
     ]
    }
   ],
   "source": [
    "model = NetResDeepBatchNorm(n_chans1=32, n_blocks=10).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "all_acc_dict[\"NetResDeepBatchNorm\"] = validate(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
